\documentclass[11pt,a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[australian,american]{babel}

\usepackage[headsepline,footsepline,automark]{scrlayer-scrpage}
\usepackage{minted}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{url}
\usepackage{titling}
\usepackage{csquotes}
\usepackage{pdfpages}
\usepackage[nomarkers,figuresonly]{endfloat}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{todonotes}
\usepackage{pdflscape}
\usepackage[hidelinks]{hyperref}

% Constants
\def\mytitle{Gossip-based dissemination, Peer Sampling Service}
\def\myauthor{Sébastien Vaucher}

\pagestyle{scrheadings}

\ihead{\headmark}
\chead{}
\ohead{\myauthor}
\cfoot{}
\ifoot{Large-Scale Distributed Systems, Assignment 1}
\ofoot{\thepage}

\posttitle{\end{center}\begin{center}\LARGE Large-Scale Distributed Systems\end{center}}

\author{\myauthor\\ \href{mailto:sebastien.vaucher@unine.ch}{sebastien.vaucher@unine.ch}}
\title{\huge \textbf{Gossip-based dissemination,\\ Peer Sampling Service}}

\hypersetup{
	pdftitle=\mytitle,
	pdfauthor=\myauthor
}

\renewcommand{\efloatseparator}{\mbox{}}

\begin{document}

\nocite{*}

\begin{titlingpage}

\begin{otherlanguage}{australian}
\maketitle
\end{otherlanguage}

\tableofcontents

\begin{table}[b]
\centering
\subfloat{\includegraphics[height=1.3cm]{jmcs.png}}
\qquad\qquad
\subfloat{\includegraphics[height=1.5cm]{unine.pdf}}
\end{table}

\end{titlingpage}

\pagebreak

\section{Introduction}

This report presents the results obtained in the first assignment of the Large-Scale Distributed Systems course taught at the University of Neuchâtel. The goal of the assignment is the implement two gossip-based dissemination algorithms, namely anti-entropy and rumor mongering. A second part of the assignment consists in implementing a peer-sampling service. The implementations are programmed in the Lua programming language, and use the Splay framework.

Apart from this report, a number of files are supplied:

\begin{description}
\item[gossip.lua]\hfill\\ Contains the entry-point of the program and the implementations of both gossip algorithms.
\item[pss.lua]\hfill\\ Contains the implementation of the peer-sampling service.
\item[gossip.sh]\hfill\\ Bash script to launch the program on a local machine.
\item[*.txt]\hfill\\ Raw logs generated by the program running on the cluster of the university.
\item[parse\_log.pl]\hfill\\ Perl script to parse logs produced by the program and generate files readable by the Gnuplot utility.
\item[gnuplot\_*.gp]\hfill\\ Gnuplot scripts generating the graphs found in this report.
\item[pss\_check\_*.rb]\hfill\\ Ruby scripts provided at the beginning of the assignment by the tutor, they are used to compute different metrics relative to the peer-sampling service. They were not modified.
\item[generate\_graphs(.sh|.bat)] Script (\textsf{.sh} for POSIX-compliant systems, \textsf{.bat} for Windows) to generate the plots found in this report from the raw logs. Note that only the \textsf{.sh} version is able to generate the plots relative to the peer-sampling service.
\end{description}

All the data presented in this report is the result of executions on the Splay cluster of the university. The conditions are near-ideal because all nodes join the network at the same time and never leave it.

For a better reading comfort, all figures are disposed at the end of the document.

\section{Gossip-based dissemination}

As part of the assignment, the anti-entropy and rumor mongering algorithms were implemented. The source code of both is contained in the file \textsf{gossip.lua}. The goal of this particular implementation is to disseminate an infection to 40 individual nodes.

\subsection{Plots}

In \autoref{fig:223-1} and \autoref{fig:223-2}, we compare the speed at which the infection reaches the nodes. \autoref{fig:223-1} shows the difference when we vary the $HTL$ parameter of the rumor mongering algorithm. This \textit{Hops To Live} value specifies how many nodes a message traverses before it stops being transmitted further. \autoref{fig:223-2}, in the other hand, shows the effect of the $F$ parameter. It states to how many random peers a given node has to propagate an incoming message. Both figures also display the performance of the anti-entropy algorithm.

Figures \ref{fig:223-1-dup}, \ref{fig:223-2-dup} and \ref{fig:223-3} display the number of duplicates metric. \autoref{fig:223-1-dup} and \ref{fig:223-2-dup} show the same execution as \autoref{fig:223-1} and \ref{fig:223-2}, respectively. The number of duplicates metric is applied to the rumor mongering algorithm. It is incremented by 1 every time a node receives a message that it already knows about. \autoref{fig:223-3} shows the number of duplicate messages needed to reach a certain number of nodes. Note that the x axis is a logarithmic scale.

\subsection{Analysis}
\label{subsec:gossip-analysis}

The first metric we are interested in is the time it takes for all nodes to be infected. With the help of Figures \ref{fig:223-1} and \ref{fig:223-2}, we can compare the performance of anti-entropy and rumor mongering. In a standard implementation of rumor mongering, the dissemination is performed immediately after receiving a message. In our case, the messages are buffered to provide a better point of comparison with anti-entropy.

The clear advantage of anti-entropy is that it will eventually reach all nodes. It is also quite fast to notify about $70\%$ of the nodes. The notification of the first $20\%$ and last $10\%$ of the nodes are slower.

With rumor mongering, it is crucial to set the stop condition according to the environment. When using the Hops To Live condition, the size of the network has to be roughly known. Figures \ref{fig:223-1} and \ref{fig:223-1-dup} display the effect of $HTL$ on performance. When using $F=2$, that is sending messages to 2 partners at a time, the $HTL$ parameter has to be large enough, 7 is our case. The number of duplicates messages generated when using a large value grows rapidly. It almost doubles when transitioning from $HTL=5$ to $HTL=7$. With small values like $HTL=1$, no duplicates are recorded. Rumor mongering with $F=2$ and $HTL=7$ is faster than anti-entropy.

The second parameter accepted by rumor mongering is called $F$. It states to how many partners a given node has to propagate received messages. Its effect on performance can be observed in Figures \ref{fig:223-2} and \ref{fig:223-2-dup}. The executions with $F=2$ and $F=3$ have suffered from a sort of \enquote{bug} during their executions. By looking at the logs\footnote{Files \textsf{rm\_f2\_h3.txt} and \textsf{rm\_f3\_h3.txt}.}, it seems that all nodes in the cluster basically decided to take a \enquote{quick nap} of 30 seconds in the middle of the execution. A second execution was performed, but yielded even worse results, with longer pauses in the execution. For the sake of the analysis, the long horizontal line in the plots should be discarded.

As far as $F$ is concerned, we can see that increasing it has a similar effect as increasing $HTL$. Increasing either parameter accelerates the dissemination at the expense of more duplicated messages. The execution with $F=1$ and $HTL=3$ did not yield any duplicates but its coverage is very poor at about $15\%$. Increasing $F$ to 2 greatly ameliorates the coverage with only a minor impact on the number of duplicates. Such a value can be a good starting point to kickstart an eventually complete gossip-based algorithm, like anti-entropy.

\autoref{fig:223-3} shows the number of duplicates needed to reach a number of nodes. Obviously, only the rumor mongering algorithm is tested. Please note that the x axis is logarithmic. This plot provides us with one conclusion: rumor mongering yields only few duplicates when we try to reach only a fraction of the nodes. However, if we want to reach all the nodes, we need to cope with a large number of duplicated messages. The effect of $F$ versus $HTL$ on the number of duplicates is undetermined, apart from the fact that higher values for either parameter bring in more duplicates.

\section{Peer-sampling service}

The second part of the assignment consists in implementing a peer-sampling service. The PSS is capable of keeping a partial view of the global system by exchanging information about peers with other peers. In our context, it is used to replace the complete view of the system used to analyze gossip-based algorithms. In accordance with the given instructions, the gossip algorithm tested with the PSS is the combination of anti-entropy and rumor mongering. For rumor mongering, $F=3$ and $HTL=3$ were taken as parameters based on the observations in \autoref{subsec:gossip-analysis}.

One execution used the \textit{rand} partner selection strategy, with all the others using \textit{tail}.

\subsection{Plots}

Figures \ref{fig:clustering} and \ref{fig:indegrees} show two metrics relative to the performance of the peer-sampling service, namely clustering and in-degrees. Figures \ref{fig:32} and \ref{fig:32-dup} display the result of integrating the PSS in the combination of anti-entropy and rumor mongering. Different couple of parameters for $H$ and $S$ are used, as well as using the complete list of nodes given by Splay.

\subsection{Analysis of PSS-related metrics}

There are three metrics solely related to the PSS in which we are interested. The first -- and most important -- is the partition of the graph of nodes. If the graph is partitioned, it means that the network is segmented in multiple parts, thus preventing some nodes to contact some other nodes. We measure the partitioning twice: once at the earliest time, when the view is composed of a random sample from the complete view; and a second time at the end of the execution, when the PSS has completed some cycles. The result that we get is that the network was only once partitioned. In the case of $H=S=0$ using the \textit{rand} strategy, one node was left out of the system at the beginning of the execution. However, the PSS was able to eventually resolve the issue, as the network was re-united at the end of the execution. This proves that the PSS algorithm is self-healing. This characteristic is crucial for real deployments where nodes come and go as they please.

The second metric is the clustering ratio. A high value (max. 1) means that the network contains aggregates, which are bad for gossip-based algorithm. On the other hand, a value of 0 indicates a perfect random graph, leading to more chances of contacting a node that never received the message in dissemination. The plot in \autoref{fig:clustering} shows the cumulative distribution of clustering for each node. The better curves are the ones that are shifted to the left. We can clearly see that a smaller clustering is offered by enabling the \textit{Swapper} removal strategy ($S>0$).

The last metric is the in-degree of the nodes. The in-degree of a node is the number of other nodes that have a pointer to the node in question. The metric is represented in \autoref{fig:indegrees}. The cumulative in-degree for each node is shown. In order to have gossip-based dissemination perform at its best, the distribution of the in-degrees across nodes has to be a Gaussian around $C$ (8 in our case). On the graph, the best curve is the most vertical one, centered around 8. The presence of either the \textit{Healer} ($H>0$) or \textit{Swapper} ($S>0$) strategy tends to provide a better distribution, with a combination of both being the best.

\subsection{Analysis of gossip-based dissemination using the PSS}

The two interesting metrics to compare executions of gossip-based dissemination algorithms are explained in \autoref{subsec:gossip-analysis}. They are the time it takes to complete the dissemination and the number of duplicate messages yielded by the rumor mongering algorithm.

The time taken by our combination of algorithms to complete the dissemination seems to be affected by how we configure the peer-sampling service. Not using either the \textit{Swapper} or the \textit{Healer} is the worst case encountered. The usage of the \textit{rand} or \textit{tail} partner selection strategy has only limited effect, with \textit{rand} being worse throughout the whole execution. The different values for $H$ and $S$ do not have an effect on the time taken by the dissemination (apart when $H=S=0$), as all executions complete in the same 2-seconds span. Using the peer-sampling service or the complete list of nodes in the network is roughly equivalent, thus indicating that a well-functioning peer-sampling service implementation is a good alternative to the utopia of possessing the complete list of nodes.

The number of superfluous messages created by the rumor mongering algorithm is definitely affected by the peer-sampling service. While all other metrics described the \textit{rand} partner selection strategy as the worst, it clearly shines when we need to reduce the number of duplicates messages. Using the complete view of the network is equally as good for the first two thirds of the nodes. Using only the \textit{Swapper} is the most duplicate-generating configuration. The other configurations curves are too noisy to draw meaningful conclusions about them.

\section{Conclusion}

The implementation of the anti-entropy and rumor mongering gossip-based dissemination algorithms presented in this report is functioning. It is able to effectively propagate a message to a network of individual nodes. The implementation of the peer-sampling service is also fully functional and capable of integrating with the two above-mentioned gossip algorithms.

The advantage of anti-entropy over rumor mongering is its eventual completeness, while the latter has an advantage in the early execution. A good working strategy is to start with rumor mongering, and then let anti-entropy finish by reaching the last nodes. Rumor mongering can be easily customized to will by tweaking its two parameters. Requiring rumor mongering to be complete inevitably yields a rapidly-increasing number of duplicated messages.

The peer-sampling service is necessary in a lot of situations involving large-scale distributed systems. In large-scale deployments, obtaining the complete list of nodes is not reasonably feasible. A PSS is a good alternative, being even better than the complete list in some cases. Configuring the PSS parameters has only a limited impact on the performance of the whole system, compared to the power of those of rumor mongering, for instance.

The analysis found in this report have to be carefully interpreted. They are the result of only a single execution on a shared platform for each set of parameters. They nonetheless provide a good estimation of the performance of each protocol.


\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{223_1.pdf}
	\caption{Variation of the $HTL$ parameter, percentage of infected nodes over time}
	\label{fig:223-1}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{223_1_dup.pdf}
	\caption{Variation of the $HTL$ parameter, duplicate messages over time}
	\label{fig:223-1-dup}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{223_2.pdf}
	\caption{Variation of the $F$ parameter, percentage of infected nodes over time}
	\label{fig:223-2}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{223_2_dup.pdf}
	\caption{Variation of the $F$ parameter, duplicate messages over time}
	\label{fig:223-2-dup}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{223_3.pdf}
	\caption{Number of duplicate messages needed to achieve a given number of infections}
	\label{fig:223-3}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{clustering.pdf}
	\caption{Clustering of the nodes}
	\label{fig:clustering}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{indegrees.pdf}
	\caption{Cumulative in-degree of the nodes}
	\label{fig:indegrees}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{32.pdf}
	\caption{Dissemination using the peer-sampling service}
	\label{fig:32}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.93\linewidth]{32_dupnodes.pdf}
	\caption{Duplicated messages while disseminating using the peer-sampling service}
	\label{fig:32-dup}
\end{figure}


\end{document}
